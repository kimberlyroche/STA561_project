{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No genre found for 366ffaa0-4522-47c0-8ef5-a9d2725538e1! Omitting it...\n",
      "No genre found for 41e95ff1-39a0-42bb-a7dc-15f96f01cc8a! Omitting it...\n",
      "No genre found for ec371192-aa97-4f8c-8eeb-b3ddbac8817e! Omitting it...\n",
      "(1029, 100, 150, 3)\n",
      "(1029, 19)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import re\n",
    "import pandas\n",
    "from pandas.core.series import Series\n",
    "\n",
    "# need to have pre-screened metadata with posters before this\n",
    "\n",
    "def get_data(input_shape):\n",
    "  directory = \"posters\"\n",
    "  meta_directory = \"metadata\"\n",
    "  no_files = len([f for f in listdir(meta_directory) if isfile(join(meta_directory, f))])    \n",
    "  x = np.empty((no_files, input_shape[0], input_shape[1], input_shape[2]))\n",
    "  y = pandas.DataFrame()\n",
    "  idx = 0\n",
    "  missing_genres = []\n",
    "  for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "      uuid = filename.split('.')[0]\n",
    "      filepath = os.path.join(directory, filename)\n",
    "      img = image.load_img(path=filepath,grayscale=False,target_size=input_shape)\n",
    "      img = image.img_to_array(img)\n",
    "      x[idx,:,:,:] = img\n",
    "      filepath = os.path.join(meta_directory, uuid + \".txt\")\n",
    "      genre_found = False\n",
    "      with open(filepath) as tsv:\n",
    "        for line in csv.reader(tsv):\n",
    "          res = re.search(\"^genre\\t(.*)$\", line[0])\n",
    "          if(res != None):\n",
    "            genres = res.group(1).split(\"\\t\")\n",
    "            if(len(genres) > 0):\n",
    "                genre_found = True\n",
    "            for g in genres:\n",
    "                y = y.append(Series({'movie':uuid, 'genre':g}), ignore_index=True)\n",
    "      if(not genre_found):\n",
    "        missing_genres.append(idx)\n",
    "        print(\"No genre found for \" + uuid + \"! Omitting it...\")        \n",
    "    idx += 1\n",
    "    y['count'] = 1\n",
    "  # remove genre-missing\n",
    "  x = np.delete(x, missing_genres, axis=0)\n",
    "  return((x,y))\n",
    "\n",
    "#input_shape = (100, 150, 3)\n",
    "\n",
    "# currently doing 50% train-test splits\n",
    "(x, y) = get_data(input_shape)\n",
    "\n",
    "y = y.pivot(index='movie', columns='genre', values='count').fillna(0)\n",
    "\n",
    "y_arr = np.array(y)\n",
    "\n",
    "print(x.shape)\n",
    "print(y_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#idx = 1\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y_arr[:,idx], test_size=0.25, random_state=1)\n",
    "\n",
    "# MNIST\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# source: https://towardsdatascience.com/a-simple-2d-cnn-for-mnist-digit-recognition-a998dbc1e79a\n",
    "# channels last with TensorFlow backend\n",
    "img_rows = 28\n",
    "img_cols = img_rows\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "#x_train = x_train.astype('float32') / 255.\n",
    "#x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "#y_train = y_train.astype('int32')\n",
    "#y_test = y_test.astype('int32')\n",
    "\n",
    "#num_classes = 2\n",
    "\n",
    "relu_leak = 0.3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(LeakyReLU(alpha=relu_leak))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(32, (5, 5)))\n",
    "model.add(LeakyReLU(alpha=relu_leak))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000))\n",
    "model.add(LeakyReLU(alpha=relu_leak))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "      optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "      metrics=['accuracy'])\n",
    "batch_size = 20\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perturb input!\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "#   height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "#   horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 53s 530ms/step - loss: 11.6050 - acc: 0.2800 - val_loss: 10.7991 - val_acc: 0.3300\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 53s 533ms/step - loss: 11.6050 - acc: 0.2800 - val_loss: 10.7991 - val_acc: 0.3300\n"
     ]
    }
   ],
   "source": [
    "# H = model.fit_generator(\n",
    "#   aug.flow(x_train, y_train, batch_size=batch_size),\n",
    "#   validation_data=(x_test, y_test),\n",
    "#   steps_per_epoch=len(x_train),\n",
    "#   epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 105s 2ms/step - loss: 0.3313 - acc: 0.9031 - val_loss: 0.1003 - val_acc: 0.9692\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 109s 2ms/step - loss: 0.0944 - acc: 0.9711 - val_loss: 0.0689 - val_acc: 0.9784\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 109s 2ms/step - loss: 0.0688 - acc: 0.9786 - val_loss: 0.0444 - val_acc: 0.9862\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# without data augmentation\n",
    "H = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# serialize model to JSON\n",
    "#model_json = model.to_json()\n",
    "#with open(\"model_action.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "#model.save_weights(\"model_action.h5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "#json_file = open('model_action.json', 'r')\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#loaded_model.load_weights(\"model_action.h5\")\n",
    "#print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "y_new = model.predict_classes(x_test)\n",
    "\n",
    "print(y_test)\n",
    "print(y_new)\n",
    "\n",
    "#for i in range(len(y_new)):\n",
    "#    print(\"Predicted=%s\" % y_new[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
